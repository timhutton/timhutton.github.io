---
layout: post
title: Post
---

<html><head><meta charset="utf-8"><title>Google+ post</title><style>body {font: 11pt Roboto, Arial, sans-serif; max-width: 640px; margin: 24px;}.author-photo {border-radius: 50%; margin-right: 10px; width: 40px;}.author {font-weight: 500;}.main-content {margin: 15px 0 15px;}.post-title {font-weight: bold;}.location {display: block; margin-top: 15px;}.location img {float: left; margin-right: 5px; width: 20px;}.media-link {display: inline-block; max-width: 100%; vertical-align: top;}.media-link p {margin-top: 5px; max-height: 4em; overflow: scroll;}.media {max-height: 100vh; max-width: 100%;}.video-placeholder {background: black; display: flex; height: 300px; max-width: 100%; width: 640px;}.play-icon {border-bottom: 30px solid transparent; border-left: 50px solid white; border-top: 30px solid transparent; color: white; margin: auto;}.album {max-height: 800px; overflow: scroll; width: calc(100vw - 48px);}.album .media-link {margin-right: 5px; max-width: 250px;}.album .media {max-height: 250px;}.link-embed {border-top: 1px solid lightgrey; display: block; margin-top: 20px;}.link-embed img {max-width: 100%;}.inline-link-embed {display: block;}.inline-link-embed img {vertical-align: middle;}.link-title {display: inline-block; font-size: medium; font-weight: 300; padding-left: 1em;}.reshare-attribution {display: block; font-weight: bold; margin-bottom: 10px;}.poll-image {margin-bottom: 5px; max-height: 300px; max-width: 500px;}.poll-choice {align-items: center; display: flex; margin-bottom: 5px; max-width: 500px;}.poll-choice-percentage {background-color: lightblue; height: 100%; left: 0; position: absolute; z-index: -1;}.poll-choice-selected {margin-right: 5px;}.poll-choice-results {border: 1px solid lightgray; border-radius: 5px; display: flex; line-height: 40px; overflow: hidden; padding: 0 8px; position: relative;}.poll-choice-results, .poll-choice-description {flex-grow: 1; margin-right: 10px;}.poll-choice-image {width: 100%;}.poll-choice-image, .poll-choice-image img {max-height: 40px; max-width: 100px;}.poll-choice-votes {max-height: 100px; overflow: auto;}.plus-entity-embed {color: black; display: block; text-decoration: none;}.plus-entity-embed-cover-photo {max-height: 300px; max-width: 100%;}.plus-entity-embed-info {padding: 0 1em 1em;}.plus-entity-embed-info h2 {font-weight: 500; margin: 10px 0;}.plus-entity-embed-info p {font-size: small; margin: 0;}.collection-owner-avatar {border-radius: 50%; border: 2px solid white; height: 40px; margin-top: -22px;}.visibility {padding: 1em 0; border-top: 1px solid grey;}.post-activity {padding: 1em 0; border-top: 1px solid grey;}.comments {border-top: 1px solid gray; padding-top: 1em;}.comment + .comment {margin-top: 1em;}.comment .media-link, .comment .inline-link-embed {margin-top: 5px;}</style></head><body><div style="margin-bottom:1em;"><div style="display:flex; align-items:center"><img class="author-photo" src="https://lh4.googleusercontent.com/-epo4ZZKNqEw/AAAAAAAAAAI/AAAAAAAAVSU/qu3LpcHEnoQ/s64-c/photo.jpg" alt="Tim Hutton"><a href="https://plus.google.com/+TimHutton" target="_blank" class="author">Tim Hutton</a> - <a target="_blank" href="https://plus.google.com/+TimHutton/posts/5KcoCS1k3pB">2014-07-23 20:26:43+0000</a><span> - Updated: 2014-07-23 20:26:43+0000</span></div><div class="main-content"></div><div><a target="_blank" href="https://plus.google.com/+AndrewDavison/posts/5FiCq5D4ceu" class="reshare-attribution">Originally shared by Andrew Davison</a>We have what we think are breakthrough results in reconstructing natural looking mosaics from a hand-held event camera (DVS) and no additional sensing.<br><br>An event camera is a silicon retina which has no global shutter. Instead, each pixel is an independent and asynchronous brightness sensor which reports an event or spike whenever it measures a threshold change in log intensity along with the microsecond-precise timing of that change.<br><br>Our approach to recovering intensity mosaics from this output is an essential SLAM one of interleaved probabilistic filters to track the pure rotation pose of the camera (incrementally, event by event) while reconstructing a gradient map of the scene --- since each event, given an estimate of camera position and velocity relative to the estimated mosaic, improves our estimate of the component of the gradient in the mosaic in the instantaneous direction of motion. The gradient map can then be upgraded to an intensity map using Poisson reconstruction. We think that essentially the same method should extend to 3D depth map estimation and visual odometry in the near future, or other sorts of motion assumption up to generic optical flow estimation.<br><br>We can reconstruct mosaics with both higher resolution than the input event stream and huge dynamic range (the video shows log intensity mosaics and gradient maps), and we should be able to track extremely rapid motion against these. We think this really proves that the DVS device is doing what it is supposed to and capturing the really important information in a moving scene --- the changes --- at a hugely reduced data rate compared to standard video, but in such a way that the whole scene can be reconstructed if needed.<br><br>This work was led by <span class="proflinkWrapper"><span class="proflinkPrefix">+</span><a class="proflink bidi_isolate" href="https://plus.google.com/109191295735101337332" oid="109191295735101337332" >Hanme Kim</a></span> with help from <span class="proflinkWrapper"><span class="proflinkPrefix">+</span><a class="proflink bidi_isolate" href="https://plus.google.com/106980339830182537380" oid="106980339830182537380" >Ankur Handa</a></span> (now in Cambridge) and collaboration with Sio-Hoi Ieng and Ryad Benosman from the Institut de Vision in Paris, and will be published at BMVC 2014. Here is the paper: <a rel="nofollow" target="_blank" href="http://www.doc.ic.ac.uk/~ajd/Publications/kim_etal_bmvc2014.pdf" class="ot-anchor bidi_isolate" jslog="10929; track:click" dir="ltr">http://www.doc.ic.ac.uk/~ajd/Publications/kim_etal_bmvc2014.pdf</a><a href="http://www.youtube.com/attribution_link?a=vtZGCCHtFpE&amp;u=/watch?v%3Dl6qxeM1DbXU%26feature%3Dshare" target="_blank" class="media-link"><div class="video-placeholder" title="Hanme Kim, Ankur Handa, Ryad Benosman, Sio-Hoi Ieng, and Andrew J. Davison. Simultaneous Mosaicing and Tracking with an Event Camera. In Proceedings of the B..."><span class="play-icon"></span></div><p>Hanme Kim, Ankur Handa, Ryad Benosman, Sio-Hoi Ieng, and Andrew J. Davison. Simultaneous Mosaicing and Tracking with an Event Camera. In Proceedings of the B...</p></a></div></div><div class="visibility">Shared with: Public</div><div class="post-activity"><div class="plus-oners">+1'd by: <a href="https://plus.google.com/+ÁngelLinaresGarcía">Ángel Linares García</a>, <a href="https://plus.google.com/+TaivoLints">Taivo Lints</a>, <a href="https://plus.google.com/108964077696785855775">Vikram Dhillon</a>, <a href="https://plus.google.com/+KevinC">Kevin C.</a>, <a href="https://plus.google.com/+ScottVorthmann">Scott Vorthmann</a></div><div class="resharers">Reshared by: <a href="https://plus.google.com/108964077696785855775">Vikram Dhillon</a></div></div></body></html>

<i>This post was originally on Google+</i>